<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: NN | Something Witty]]></title>
  <link href="http://ElPiloto.github.io/blog/categories/nn/atom.xml" rel="self"/>
  <link href="http://ElPiloto.github.io/"/>
  <updated>2014-10-06T13:24:57-04:00</updated>
  <id>http://ElPiloto.github.io/</id>
  <author>
    <name><![CDATA[Luis R. Piloto]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[(PDP) Dan Yamins: Object recognition]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/10/03/dan-yamin-object-recognition/"/>
    <updated>2014-10-03T10:34:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/10/03/dan-yamin-object-recognition</id>
    <content type="html"><![CDATA[<p>Computation models of vision</p>

<p>challenging computational problems:</p>

<p>view: position, size, pose and illumination</p>

<p>clutter and occlusion</p>

<p>distortion and noise</p>

<p>object category hierarchy: basic categories + individual identification of category members (category = car, identify honda civic, toyota corolla, etc)</p>

<p>pixel –&gt; RGC –&gt; LGN –&gt; V1 –&gt; V2 –&gt; V4 –&gt; IT (at some point, task has been solved)</p>

<p>high-variation test image set:</p>

<p>objects on complex background (64 objects, 8 from 8 categories), presented on uncorrelated realistic backgrounds</p>

<p>create images with different degrees of variation: 
low-variation: size/pose/position/illumination are normalized
high-variation: size/pose/position/illumination can vary pretty widely</p>

<p>subsequently recorded from macaque V4 and IT: 300 units recorded</p>

<p>output = binned spike counts in 70ms - 170ms, averaged over 25-50 reps of each image</p>

<p>trained linear classifier on recordings from IT and V4 and varied variation levels of images, found that IT-based classifier basically tracks human performance   </p>

<p>Lower areas (RGC, LGN, V1) have been reaosnably explained by models (~50% explained variance)   </p>

<p><strong>general idea:</strong> start off with code in early cortex, eventually gets transformed to a linearly decodable code, let’s try to see what transformation supports that</p>

<p>Modeling: look at performance (can do object recognition tasks) and neural predictivity (do individual layers of model correlate with corresponding layers of cortex?)   </p>

<p>Instead, optimize for performance, and then <em>exo facto</em> look at how it predicts neural responses   </p>

<p>Architectural Parameters: Hierarchical Convolutional Networks</p>

<p>filter, theshold and saturate, pool, and normalize</p>

<p>filter: kernel size, how many filters
pooling: what kind of pooling
normalizing: do we normalize at all</p>

<p>neural predictivity: predict each unit as a linear combination of model outputs (for a given layer)</p>

<p>HT experiments: tried 3 methods of training hiearchical convolutional neural network</p>

<ol>
  <li>random selection of models;  look at neural predictivity </li>
  <li>optimizie models for performance; look at neural predictivity</li>
  <li>optimize for IT predictivity;</li>
</ol>

<p>look at performance on task vs. IT predictivity for 1 through 3  <br />
method 3 didn’t do much better than method 2    </p>

<p>but more than anything: any of the models aren’t doing that well looking at performance vs IT predictivity, so how do we improve performance?   </p>

<p>try boosting (hierarchical modular optimization): some architectures are good at individual object recognition sub-tasks (faces vs. boats, buildings vs. flowers, etc) so let’s try to combine them,   </p>

<p>their hypothesis: ability to perform sub-tasks (even though they’re on a different trainig data set, specifically different categories and simpler background), finds a basis set with which a combined model can perform maximally</p>

<p>this gets up to 50-65% variance explained of IT, next question V4 to model layer fit isn’t great - but actually intermediate layer in model “model V3” explains V4 - so what are the transformations that happen there? still trying to figure it out, suggestion by jon cohen: “statistical topology”   </p>

<p>STATISTICAL TOPOLOGICAL DATA ANALYSIS USING PERSISTENCE LANDSCAPES</p>

<p>Statistical topology</p>
]]></content>
  </entry>
  
</feed>
