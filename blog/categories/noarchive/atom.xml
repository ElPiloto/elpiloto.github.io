<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: noarchive | Something Witty]]></title>
  <link href="http://ElPiloto.github.io/blog/categories/noarchive/atom.xml" rel="self"/>
  <link href="http://ElPiloto.github.io/"/>
  <updated>2014-10-06T15:53:24-04:00</updated>
  <id>http://ElPiloto.github.io/</id>
  <author>
    <name><![CDATA[Luis R. Piloto]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Sleep EEG: LOSO (post-bug) and ERP]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/10/06/sleep-eeg-loso-post-bug-and-erp/"/>
    <updated>2014-10-06T10:29:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/10/06/sleep-eeg-loso-post-bug-and-erp</id>
    <content type="html"><![CDATA[<h3 id="as-described-in-a-hrefhttpelpilotogithubioblog20140925sleep-eeg-replicating-best-p-val-resultsthis-posta-there-was-a-bug-that-messed-things-up-for-the-results-posted-a-hrefhttpelpilotogithubioblog20140904sleep-eeg-finding-optimal-wake-pattern-for-sleep-transformherea">As described in <a href="http://ElPiloto.github.io/blog/2014/09/25/sleep-eeg-replicating-best-p-val-results/">this post</a>, there was a bug that messed things up for the results posted <a href="http://ElPiloto.github.io/blog/2014/09/04/sleep-eeg-finding-optimal-wake-pattern-for-sleep-transform/">here</a></h3>

<p>In general, we were producing a non-random, though erroneous, transformation to our data so now that that bug is fixed we should be getting pretty similar results just along different times and frequencies.   </p>

<h4 id="nothing-has-changed-for-the-optimal-lambda-choice">Nothing has changed for the optimal lambda choice:</h4>
<p>Still seems pretty close between the two, but let’s stick with <a href="http://ElPiloto.github.io/images/research/LOSO_POSTBUG/LOSO_WAKE_LOGREG_POST_BUG_face_sceneAUC_lambda10.png">$\lambda = 10$</a> over <a href="http://ElPiloto.github.io/images/research/LOSO_POSTBUG/LOSO_WAKE_LOGREG_POST_BUG_face_sceneAUC_lambda50.png">$\lambda = 50$
</a></p>

<h4 id="looking-for-best-timebin-and-frequency">Looking for best timebin and frequency:</h4>
<p>previously we liked <strong>300 ms</strong> time bin and were slightly frequency agnostic based on <a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_PVAL_face_sceneAUC_lambda10.png">this</a>, but now we get totally different looking results:</p>

<p><a href='/images/research/LOSO_POSTBUG/LOSO_WAKE_LOGREG_POST_BUGPVAL_face_sceneAUC_lambda10.png' target='_blank'><img src="/images/research/LOSO_POSTBUG/LOSO_WAKE_LOGREG_POST_BUGPVAL_face_sceneAUC_lambda10.png" width="700" height="350"></a></p>

<p><strong>Thoughts:</strong> Cool things: we’re getting something around when you’d expect to see the N170 for faces!  We were getting hints of this when we were doing individual subject classification, but it seems that this is the only thing from the <a href="http://ElPiloto.github.io/images/research/sleep_eeg_hilbert/wake_hilb_mean_across_subjects.png">subject-specific classification</a> that comes through in the LOSO analysis (although we also get other strongly classifiable time bins in the LOSO analsis, it’s just that those didn’t pop out in the subject-specific classification results).  <strong>SO</strong>, I say let’s generate transformed sleep data plotaccording to four or five different patterns: 
	- something in the 4 Hz, 125-275 ms timebin range
	- something in the 4 Hz, 450-600 ms timebin range
	- something in the 4 Hz, 725-925 ms timebin range
	- something in the 8 Hz, 100-175 ms timebin range 
	- something in the 8 Hz, 275-325 ms timebin range   </p>

<p>This will be A LOT of plots to look at, but if we see something we can always check on James’ second batch of spindle-cued subjects.</p>

<h4 id="lets-look-at-the-recursive-feature-analysis-results-for-lambda--10">Let’s look at the recursive feature analysis results for $\lambda = 10$</h4>
<p>And see what’s the best we get across the different time bins for the 4 Hz and 8 Hz frequencies at some points that we cared about - I’m working on presenting these in a better fashion but for now these are the plots that were most easily generated:    </p>

<p><strong>Time = 150ms</strong>
<a href='/images/research/LOSO_POSTBUG/LOSO_RFE_LAMBDA<em>10</em>150ms.png' target='_blank'><img src="/images/research/LOSO_POSTBUG/LOSO_RFE_LAMBDA<em>10</em>150ms.png" width="700" height="350"></a>   </p>

<p><strong>Time = 300ms</strong>
<a href='/images/research/LOSO_POSTBUG/LOSO_RFE_LAMBDA<em>10</em>300ms.png' target='_blank'><img src="/images/research/LOSO_POSTBUG/LOSO_RFE_LAMBDA<em>10</em>300ms.png" width="700" height="350"></a>   </p>

<p><strong>Time = 475ms</strong>
<a href='/images/research/LOSO_POSTBUG/LOSO_RFE_LAMBDA<em>10</em>475ms.png' target='_blank'><img src="/images/research/LOSO_POSTBUG/LOSO_RFE_LAMBDA<em>10</em>475ms.png" width="700" height="350"></a>   </p>

<p><strong>Time = 775ms</strong>
<a href='/images/research/LOSO_POSTBUG/LOSO_RFE_LAMBDA<em>10</em>775ms.png' target='_blank'><img src="/images/research/LOSO_POSTBUG/LOSO_RFE_LAMBDA<em>10</em>775ms.png" width="700" height="350"></a>   </p>

<h4 id="additionally-lets-look-at-wake-loso-classification-using-just-erps">Additionally, let’s look at wake LOSO classification using just ERPs:</h4>
<p>Well, this is awkward: our best classification results are for using the ERPs: 68% accuracy.</p>

<p><a href='/images/research/LOSO_POSTBUG/LOSO_WAKE_LOGREG_ERP25_face_sceneAUC_lambda10.png' target='_blank'><img src="/images/research/LOSO_POSTBUG/LOSO_WAKE_LOGREG_ERP25_face_sceneAUC_lambda10.png" width="700" height="350"></a></p>

<h4 id="lastly-lets-not-forget-that-we-wanted-to-look-at-16-hz-175-ms-in-the-sleep-data-because-we-did-well-with-it-on-an-individual-subject-level-as-seen-here">Lastly, let’s not forget that we wanted to look at 16 Hz, 175 ms in the sleep data because we did well with it on an individual subject level as seen here:</h4>

<p><a href='/images/research/sleep_eeg_hilbert/sleep_hilb_mean_across_subjects_lambda1.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/sleep_hilb_mean_across_subjects_lambda1.png" width="700" height="350"></a></p>

<p><strong>TODO:</strong></p>

<ul>
  <li>when picking number of electrodes to keep, err on the side of too many so that we get a varied distribution of importance weights (so that we can do correlation)</li>
  <li>generate sleep similarity plots BY wednesday!</li>
  <li>let’s look at RFE and ERP results, too and generate a template based on that as well!</li>
  <li>let’s do whatever we can to help James preprocess the validation subjects</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sleep EEG: Replicating best p-val results]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/09/25/sleep-eeg-replicating-best-p-val-results/"/>
    <updated>2014-09-25T14:51:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/09/25/sleep-eeg-replicating-best-p-val-results</id>
    <content type="html"><![CDATA[<h3 id="we-are-trying-to-replicate-these-results-below">We are trying to replicate these results below:</h3>

<h4 id="so-far-ive-tried">So far I’ve tried:</h4>
<ul>
  <li>Running the same exact analysis (driver_LOSO_replicate_PVAL.m)   </li>
  <li>Running the same exact analysis but only classifying between faces and scenes via:
<code>preprocessing.type_specifics_args.classes = [1 2];</code>    <br />
    <ul>
      <li>this did not help   </li>
    </ul>
  </li>
  <li>Try loading up results from Sept 09, and regenerating plots - will indicate whether or not something changed in plots or results. <br />
    <ul>
      <li>Doing this, I’ve found that the results of interest are specifically in this file:  <br />
<code> 09-Sep-2014_14_04_44LOSO_WAKE_logreg_sweep.mat </code>   </li>
      <li>I’ve found that it is in fact for $ \lambda = 10 $ (I was worried I might have accidentally documented the wrong value of $\lambda$)       </li>
      <li>We were classifying against all 5 classes (validating our findings above that classifying only faces vs scenes did not reproduce the results)   </li>
    </ul>
  </li>
  <li>Try duplicating exact time range used originally, perhaps there is some bug in my code <br />
    <ul>
      <li><strong>BAD NEWS:</strong> this reproduced the results, meaning there has to be some BUG in my code where I reshape the data, append subject data together, OR iterate through individual timebins and frequencies. This is why it would be nice to have the time to create some simulated data.</li>
    </ul>
  </li>
</ul>

<h3 id="fixing-the-damn-bug">FIXING THE DAMN BUG</h3>
<p>Relevant files:  </p>

<p>So far, I’ve ensured that when I reshape and permute the subject’s data after loading it (<code>get_preprocessed_subj_data.m, Line: 128 </code>), that I have not messed up the ordering of the data.</p>

<p>Next: when I filter timebins out, do I mess that process up?  This also checks out(<code>get_preprocessed_subj_data.m, Line: 60 </code>)   </p>

<p>Next: what about when I call <code>iterate_over_data</code>?  The data was misordered here, so somewhere between <code>get_preprocessed_subj_data</code> and <code>iterate_over_data</code> we messed things up.</p>

<p>Next: let’s check that the anonymous function that is used for reshaping the data (after it’s been flattened) is correct, this gets used in a few places.  YEP, this is the problem: someone please kindly shoot me in the face.   </p>

<h3 id="bug-the-sequel-discrepancy-between-the-recursive-feature-elimination-results-and-logistic-regression-results">BUG, The Sequel: DISCREPANCY BETWEEN THE RECURSIVE FEATURE ELIMINATION RESULTS AND LOGISTIC REGRESSION RESULTS</h3>
<p>I’ve verified that there is no discrepancy between the accumulated values and the plotted values, so it does not seem to be the case that the plotting function is messing things up.   </p>

<p>Recursive feature elimination (RFE) analysis has a setting for the minimum number of features i.e. remove features until we hit some minimum number of features.  In general, this is set to 1, so that we can see the effect of removing 0 to all but one features (electrodes).  I have found that if I set that value to 60 (only removing 4 features), then the RFE results align with the logistic regression results, however, if I set that to 1 or even just 50, the results stop lining up.  Very, very perplexing.    </p>

<p>Next, let’s look at the features used for the first and second iteration with different settings (60 and 50) of the minimum number of features.  If they differ in any way, then the code for removing features must be incorrect and we can delve into that.<br />
   - So for the second iteration, the fourth frequency, the RFE results have different features they’ve removed.  WTF, mate?   A reasonable next step would be to look at the values passed into the <code>remove_unused_features</code> for both parameter settings and see if they are the same.</p>

<p>Looking at the classifier weights for the first iteration of the fourth frequency for both parameter settings, we see that they have different values, so naturally removing features would produce different removed features for the second iteration.  Additionally, this implies there is something different being fed into the classifier for the first iteration that is producing different feature weights.</p>

<p><strong>HERE IT IS:</strong>  Currently, we’ve been doing an RFE iteration (going from 64 features down to minimum num_features) for each frequency bin (2 Hz all the way up to 32 Hz).  To maintain the correct level of regularization, we take the max number of features (64) and look at the ratio of regularization (usually 10) to the number of features and keep this proportional as we remove more and more features.  The bug was that between RFE iterations (i.e. starting anew at 4 Hz, after doing 2 Hz), the regularization ratio was calculating using the previous iteration’s last number of features (not the max number of features) - so as we moved from 2 Hz to 32 Hz, our results got more and more skewed from the regular logistic regression results because we were using much smaller regularization.  This is fixed now!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sleep EEG: James Visit Recap and Brainstorm]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/09/18/sleep-eeg-james-visit-recap-and-brainstorm/"/>
    <updated>2014-09-18T14:49:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/09/18/sleep-eeg-james-visit-recap-and-brainstorm</id>
    <content type="html"><![CDATA[<h4 id="regarding-this-our-best-result-during-sleep-is-058---but-were-messed-up-by-multiple-comparisons">Regarding this, our best result, during sleep, is 0.58 - but we’re messed up by multiple comparisons</h4>
<p>TODO: we can use our a priori best itmebin and frequency to analyze James’ new dataset (timebin 175ms, freq 16)</p>

<p>Cephalapod L1 vs L2</p>

<p>http://elpiloto.github.io/images/research/sleep_eeg_hilbert/sleep_hilb_mean_across_subjects_lambda1.png</p>

<ul>
  <li>
    <p>negative peak of a slow-wave, phase of 0.6 - 1.2 Hz</p>
  </li>
  <li>
    <p>how similar are frequency band patterns to each other?</p>
  </li>
</ul>

<p>N170 is really sharp, maybe at 8 Hz and 225ms, large over Cz sometimes (doesn’t make a lot of sense anatomically - you’d expect it to be over occipital)</p>

<p>once we get the template, we want to inspect them, although it’s hard to know what to expect</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sleep Transform ALL the Subjects]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/09/10/sleep-transform-all-the-subjects/"/>
    <updated>2014-09-10T11:35:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/09/10/sleep-transform-all-the-subjects</id>
    <content type="html"><![CDATA[<h2 id="transformation-outline">Transformation Outline</h2>

<p>In this <a href="http://ElPiloto.github.io/blog/2014/09/04/sleep-eeg-finding-optimal-wake-pattern-for-sleep-transform/">post</a> we decided we’re going to try to generate a wake template for all of the different frequency bands at the <strong>300ms time bin</strong>.  Recall that those results were for L2-regularization of LOSO data ( with $\lambda = 10$ giving us the best results )  Below we outline how we plan to transform the sleep data.</p>

<pre>
# for now, we're going to do a sleep transformation classification for each frequency
# for later: concatenate transformed data at each frequency into a single dataset
foreach frequency band wake_F:
	foreach electrode E:
		if pval( mean_power_faces[E] - mean_power_scenes[E] ) &lt; 0.05
			informative_electrodes.add_electrode(E)
	
	wake_data = append_subject_data(freq = wake_F, timebin = 300ms, electrodes = informative_electrodes,
				classes_to_use = [faces scenes objects scrambled_faces scrambled_scenes])
	
	wake_logreg = train_logistic_regression_classifier(wake_data, lambda = 10)

	# we could also take the mean pattern as our wake template
	wake_template = get_importance_map(wake_logreg, class = faces)
	
	# Option 1: old-school sleep transform analysis
	foreach subject S:
		foreach pattern P in sleep_data[S]:

			filtered_pattern = remove_noninformative_electrodes(P, informative_electrodes)

			foreach timebin T:
				foreach frequency sleep_F:

					transformed_sleep_data[S,P,T,sleep_F] = dot_product( wake_template, filtered_pattern[T,sleep_F] )
				
				# note below we are only grabbing data for THIS subject and THIS timebin - meaning a classifier
				# score for each timebin
				sleep_logreg[T] = train_logistic_regression_classifier(transformed_sleep_data[S,all_patterns,T, all_frequencies],
											lambda = ?, cross_validation = leave-one-trial-out)
	
	# Option 2: LOSO sleep transformed
	LOSO_sleep_logreg = train_logistic_regression_classifier(transformed_sleep_data, lambda = ?, cross_validation = per_subject)

	# Option 3: Use all sleep times as a single pattern (nice b/c get single classification score per trial)
</pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sleep EEG Finding Optimal Wake Pattern For Sleep Transform]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/09/04/sleep-eeg-finding-optimal-wake-pattern-for-sleep-transform/"/>
    <updated>2014-09-04T10:06:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/09/04/sleep-eeg-finding-optimal-wake-pattern-for-sleep-transform</id>
    <content type="html"><![CDATA[<h2 id="wake-loso-log-reg-150ms---550ms-time-freq-sweep-on-hilbert-transformed-data">WAKE LOSO LOG REG 150ms - 550ms Time Freq. Sweep On Hilbert Transformed data</h2>

<p>Find those results below.  It seems that across the board, looking at diffAUC, we get that the 300ms timebin is the best.  However, one of the goals of this analysis was to see if there was any variability in when faces are classifiable compared to when scenes are classifiable.  Towards this end, we plot the AUC on a per class basis.  That is, we look at the AUC calculating the face classifier output for faces as positive instances, and the face classifier output for scenes as negative instances.  Similarly, we do this for scenes.  When we look at this across all subjects, we find that the 300ms timebin strong diffAUC is actually driven by strong faceAUC(~0.58) for that timebin and not at all by the sceneAUC(~0.43).  Thus, if we do decide to proceed with sleep transforming, we should only face transform at 300ms.   When we look at the faceAUC per subject, we find that 300ms at the 30Hz band is the good for all but two subjects (08 and 22).  This is encouraging!  Feel encouraged.  Did it work? Are you encouraged?  Fine.  Nevermind.  Whatever.  </p>

<p>I ran this analysis with a shortened time window, I’m re-running the analysis with the full time window to make sure that scenes aren’t doing well during the later periods.  Additionally, we have always been z-scoring across electrodes, I’m not doing that for this new analysis just to make sure our z-scoring decision (supported via our first pilot) are still valid.  I can look at the difference between the new results and the results below for the timebins they overlap to see the effect of z-scoring.   </p>

<p><strong>TLDR;</strong><br />
- diffAUC points to timebin 300ms as best time across all subjects with average diffAUC = 0.58 <br />
- looking into faceAUC vs. sceneAUC, it’s clear that the diffAUC is entirely driven by faceAUC (i.e. scenes aren’t above chance at 300ms), we should sleep transform sleep data using the 300ms timebin importance maps.   </p>

<p><strong>QUESTIONS TO ANSWER</strong> <br />
1. does one-sample, one-tailed t-test reveal better bins? <br />
2. are there better times? <br />
3. is there a difference between z-scoring and not z-scoring across channels? <br />
4. do we get better results for lower lambdas?   </p>

<p><strong>ANSWERS TO QUESTIONS</strong> <br />
<strong>ONE.</strong> We still get the best time bin to be 300 ms <a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_PVAL_face_sceneAUC_lambda100.png">if you look at the p-values</a> instead of the <a href="http://ElPiloto.github.io/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__face_sceneAUC_lambda100.png">mean across subjects</a>  <br /></p>

<p><strong>TWO.</strong> When we do the same analysis looking at time bins 550ms - 1000ms, we don’t get anything better.  There’s a random blip around 950ms for scenes    <a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_Q2_ZSCOREPVAL_face_sceneAUC_lambda50.png">here</a>, but it’s not any better than what we saw for the 150ms - 550ms case.     <br /></p>

<p><strong>THREE.</strong> YES IT DOES.  Compare these two plots WITHOUT z-scoring to their respective plots under question 4.  <br /></p>
<center>
<a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_Q3_ZSCOREPVAL_face_sceneAUC_lambda50.png">$\lambda = 50$</a><br />
<a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_Q3_ZSCOREPVAL_face_sceneAUC_lambda100.png">$\lambda = 100$</a><br />
</center>

<p><strong>FOUR.</strong>  We get better results with lambda = 10 for the p-val AUC plots, but not by too much if we just look at the mean AUC across subjects.  <strong>Let’s go with 10 for a wake transform</strong>    </p>
<center>
<a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_PVAL_face_sceneAUC_lambda1.png">$ \lambda = 1$</a><br />   
<a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_PVAL_face_sceneAUC_lambda10.png">$ \lambda = 10$</a><br />   
<a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_PVAL_face_sceneAUC_lambda50.png">$ \lambda = 50$</a><br />   
<a href="http://ElPiloto.github.io/images/research/LOSO_sleep_transform/LOSO_WAKE_LOGREG_SWEEP_PVAL_face_sceneAUC_lambda100.png">$ \lambda = 100$</a><br />   
</center>

<p><strong>Ken Reply</strong></p>

<p>i like the idea of finding the best time/freq for faces and then using
that for a sleep transform. i agree that 300ms / 30hz looks like the
best candidate for the “face champion”.    </p>

<p>before you do the sleep transform, it would be great if you could run
the same analysis that you just ran, but for lower lambda vals (say 1,
10, 50). it looks like things were definitely getting worse as you
increased lambda in the analyses that you just ran, so maybe the best
lambda vals for this analysis are &lt; 100.    </p>

<p>if 300ms / 30hz still looks good with other lambda vals, then let’s
sleep transform using that.    </p>

<p>if we go ahead with 300ms / 30hz for the transformation, then i
recommend first filtering out uninformative electrodes, and then
re-running the classifier on the leftover electrodes and either 1)
using the importance map values for faces as the template, or 2) using
the mean pattern values (for faces) as the template. i also recommend
sticking with our original plan of grabbing the spatial pattern from
the BEST frequency band (e.g., 30hz) at the best time point (e.g.,
300ms) as opposed to grabbing ALL of the frequency-specific spatial
patterns from the best time point. we can use this pattern to
transform all of the frequences in the sleep data.     </p>

<p>also, after you do the sleep transform, i am interested in looking at
timecourses for reactivation as opposed to jumping right into crossval
accuracy.    </p>

<h2 id="lambda--100">Lambda = 100</h2>

<h4 id="diffauc-face-minus-scene">diffAUC (face minus scene)</h4>

<p><a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__diffAUC_lambda100.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__diffAUC_lambda100.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__face_sceneAUC_lambda100.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__face_sceneAUC_lambda100.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__faceAUC_per_subj_lambda100.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__faceAUC_per_subj_lambda100.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__sceneAUC_per_subj_lambda100.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__sceneAUC_per_subj_lambda100.png" width="700" height="350"></a></p>

<h2 id="lambda--500">Lambda = 500</h2>

<h4 id="diffauc-face-minus-scene-1">diffAUC (face minus scene)</h4>

<p><a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__diffAUC_lambda500.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__diffAUC_lambda500.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__face_sceneAUC_lambda500.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__face_sceneAUC_lambda500.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__faceAUC_per_subj_lambda500.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__faceAUC_per_subj_lambda500.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__sceneAUC_per_subj_lambda500.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__sceneAUC_per_subj_lambda500.png" width="700" height="350"></a></p>

<h2 id="lambda--1000">Lambda = 1000</h2>

<h4 id="diffauc-face-minus-scene-2">diffAUC (face minus scene)</h4>

<p><a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__diffAUC_lambda1000.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__diffAUC_lambda1000.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__face_sceneAUC_lambda1000.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__face_sceneAUC_lambda1000.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__faceAUC_per_subj_lambda1000.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__faceAUC_per_subj_lambda1000.png" width="700" height="350"></a>
<a href='/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__sceneAUC_per_subj_lambda1000.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/WAKE_LOSO_logreg__sceneAUC_per_subj_lambda1000.png" width="700" height="350"></a></p>

]]></content>
  </entry>
  
</feed>
