<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: relational RL | Something Witty]]></title>
  <link href="http://ElPiloto.github.io/blog/categories/relational-rl/atom.xml" rel="self"/>
  <link href="http://ElPiloto.github.io/"/>
  <updated>2014-08-10T16:53:45-04:00</updated>
  <id>http://ElPiloto.github.io/</id>
  <author>
    <name><![CDATA[Luis R. Piloto]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Relational RL]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/08/10/relational-rl/"/>
    <updated>2014-08-10T16:12:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/08/10/relational-rl</id>
    <content type="html"><![CDATA[<h2 id="motivation">Motivation</h2>

<p>Why do we even care about relational reinformcent learning?  </p>

<ol>
  <li>
    <p><em>Rule Learning by Seven-Month-Old Infants.</em> Marcus, Vijayan, Rao, &amp; Vishton, 1999: <strong>Methods:</strong>  <br />
7-month old infants were exposed to sentences of the form: ABB or ABA during a training phase (e.g. “ga ti ti” or “ga ti ga”), testing phase entailed consistent or inconsistent conditions where presented with entirely new words either in ABB or ABA format (e.g. “wo fe fe” or “wo fe wo”). <br />
<strong>Results:</strong> Infants looked longer at flashing light during inconsistent sentences in test period ( e.g. train “ABB”, test “ABA”) compared to consistent.<br />
<strong>Discussion:</strong> This indicates rule learning in infants, cannot be explained by statistical learning of transition probabilities because test set consisted entirely of new words (no estimate of transition probability).  Requires extraction of relationships: are these two entities the same?  </p>
  </li>
  <li>
    <p>Can generalize relationships over identities of objects in the world - variable abstraction.</p>
  </li>
  <li>
    <p>Introspection: our own capacities for abstraction and transfer suggest the importance of symbolic processing (Buchheit, 1999).</p>
  </li>
  <li>
    <p>Allows rich, intuitive specification of background knowledge: facilitating learning to new tasks (via bootstrapping from previously learned experiences): using a key on a lock is not dependent on the particular task at hand: if we learn through trial and error the abstract transition model: $ T(isLocked(lock) = true, unlocks(lock,key) = true, useKeyOnLock(lock,key)) \rightarrow  isLocked(lock) = false$</p>
  </li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Probabilistic Logic Learning - Luc De Raedt and Kristian Kersting]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/08/05/probabilistic-logic-learning-luc-de-raedt-and-kristian-kersting/"/>
    <updated>2014-08-05T12:51:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/08/05/probabilistic-logic-learning-luc-de-raedt-and-kristian-kersting</id>
    <content type="html"><![CDATA[<h4 id="what-does-probabilistic-logic-learning-mean">What does probabilistic logic learning mean?</h4>
<p><strong>probabilistic</strong> - probabilistic representations and reasoning mechanisms <br />
<strong>logic</strong> - first order logical and relational representations (compared to propositional logic affords reasoning about objects)</p>

<h3 id="logic-glossary">Logic Glossary</h3>
<p>first-order logic $\leftrightarrow$ relational representation <br />
allows for:<br />
<strong>extensional</strong>: <code>ram(r1,c1)</code> – </p>
]]></content>
  </entry>
  
</feed>
