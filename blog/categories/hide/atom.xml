<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: hide | Something Witty]]></title>
  <link href="http://ElPiloto.github.io/blog/categories/hide/atom.xml" rel="self"/>
  <link href="http://ElPiloto.github.io/"/>
  <updated>2014-08-10T16:53:45-04:00</updated>
  <id>http://ElPiloto.github.io/</id>
  <author>
    <name><![CDATA[Luis R. Piloto]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Relational RL]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/08/10/relational-rl/"/>
    <updated>2014-08-10T16:12:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/08/10/relational-rl</id>
    <content type="html"><![CDATA[<h2 id="motivation">Motivation</h2>

<p>Why do we even care about relational reinformcent learning?  </p>

<ol>
  <li>
    <p><em>Rule Learning by Seven-Month-Old Infants.</em> Marcus, Vijayan, Rao, &amp; Vishton, 1999: <strong>Methods:</strong>  <br />
7-month old infants were exposed to sentences of the form: ABB or ABA during a training phase (e.g. “ga ti ti” or “ga ti ga”), testing phase entailed consistent or inconsistent conditions where presented with entirely new words either in ABB or ABA format (e.g. “wo fe fe” or “wo fe wo”). <br />
<strong>Results:</strong> Infants looked longer at flashing light during inconsistent sentences in test period ( e.g. train “ABB”, test “ABA”) compared to consistent.<br />
<strong>Discussion:</strong> This indicates rule learning in infants, cannot be explained by statistical learning of transition probabilities because test set consisted entirely of new words (no estimate of transition probability).  Requires extraction of relationships: are these two entities the same?  </p>
  </li>
  <li>
    <p>Can generalize relationships over identities of objects in the world - variable abstraction.</p>
  </li>
  <li>
    <p>Introspection: our own capacities for abstraction and transfer suggest the importance of symbolic processing (Buchheit, 1999).</p>
  </li>
  <li>
    <p>Allows rich, intuitive specification of background knowledge: facilitating learning to new tasks (via bootstrapping from previously learned experiences): using a key on a lock is not dependent on the particular task at hand: if we learn through trial and error the abstract transition model: $ T(isLocked(lock) = true, unlocks(lock,key) = true, useKeyOnLock(lock,key)) \rightarrow  isLocked(lock) = false$</p>
  </li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sleep EEG: Hilbert Transformed Data]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/08/06/sleep-eeg-hilbert-transformed-data/"/>
    <updated>2014-08-06T10:36:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/08/06/sleep-eeg-hilbert-transformed-data</id>
    <content type="html"><![CDATA[<h2 id="wake-hilbert-transformed-classification">Wake Hilbert Transformed Classification</h2>

<p><a href='/images/research/sleep_eeg_hilbert/wake_hilb_mean_across_subjects.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/wake_hilb_mean_across_subjects.png" width="700" height="350"></a></p>

<p><strong>Figure 1:</strong> Average AUC on Hilbert-transformed wake data across all subjects for each time bin and frequency band combination.</p>

<p><strong>Thoughts:</strong> We see “hotspots” where we were hoping to see them: at the theta frequency around 200-230ms. Moreover, we see that the 200-230ms theta bin forms a local peak: as you move earlier or later in time, classification accuracy decreases.  Importantly, the accuracy using these bands (as opposed to individual frequencies like we had before) yields comparable average wake classification across subjects if we look at this <a href="http://ElPiloto.github.io/images/research/sleep_eeg_9_subjects_06_23_2014/wake_auc_avgd.png">old plot</a>.  If this result holds for all subjects, then we would feel pretty good about using the 200ms (or 230ms) theta time-freq bin to transform the sleep data.  Therefore, let’s look at the individual subjects to see if these results are driven by some subjects or if they seem to be pretty evenly distributed (spoiler: doesn’t seem to be a good time-freq bin, or even classifiable, for all subjects, but it does pretty well)</p>

<p><a href='/images/research/sleep_eeg_hilbert/wake_hilb_all_subjects_all_freqs_all_times.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/wake_hilb_all_subjects_all_freqs_all_times.png" width="700" height="350"></a></p>

<p><strong>Figure 2:</strong> AUC heatmaps of classification AUC per subject.  Subject IDs are along the top of each subplot, timebins run along the y-axis and frequencies along the x-axis (only explicitly marked for the last subject, but the axes are exactly the same as Figure 1).</p>

<p><strong>Thoughts:</strong> These plots, though informative, suck for the purpose of evaluating how good the 200-250ms, theta bins do across all subjects.  Let’s zoom in on the areas of interest below.  One additional point, is that we’re getting <strong>much</strong> better max AUC across timebins than previously before (using individual frequencies) suggesting that the Hilbert transform is a better preprocessing technique for classification.</p>

<p><a href='/images/research/sleep_eeg_hilbert/wake_across_subjs_times7<strong>8</strong>9_freq2.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/wake_across_subjs_times7<strong>8</strong>9_freq2.png" width="700" height="350"></a></p>

<p><strong>Figure 3:</strong>  Above we show the AUC for each subject for 3 different times (200, 225, and 250ms respectively) for the 4 Hz (theta) frequency band.</p>

<p><strong>Thoughts:</strong> This isn’t the greatest, especially considering some subjects have time-freq bins with much higher AUC.  “Irregardless,” these results are sufficiently positive to justify transforming sleep data.  Everything that we said about the non-band wake analyses holds here (e.g. we can look at other bins that look good for subjects, we can take each subject’s best bin to transform the data, etc).</p>

<h2 id="sleep-hilbert-untransformed-classification---sweep-across-time-and-frequency-combinations">Sleep Hilbert Untransformed Classification - Sweep Across Time And Frequency Combinations</h2>

<p>Below we look at how discriminable the sleep data is at each particular timebin and frequency combination of the sleep data using logistic regression.  Additionally, we test the regularization parameter for two separate values $ \lambda = 1, 50 $</p>

<p><a href='/images/research/sleep_eeg_hilbert/sleep_hilb_mean_across_subjects_lambda1.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/sleep_hilb_mean_across_subjects_lambda1.png" width="700" height="350"></a></p>

<p><strong>Figure 4:</strong> Above we show the across-subjects average AUC for performing logistic regression on the sleep data at each time and frequency band combination with regularization parameter $ \lambda = 1 $.</p>

<p><a href='/images/research/sleep_eeg_hilbert/sleep_hilb_lambda50_mean_across_subjects.png' target='_blank'><img src="/images/research/sleep_eeg_hilbert/sleep_hilb_lambda50_mean_across_subjects.png" width="700" height="350"></a></p>

<p><strong>Figure 5:</strong> Same as Figure 4, except this time we set the regularization parameter $ \lambda = 50 $.</p>

<p><strong>Thoughts:</strong> The band around 175ms, 16 Hz looks promising - we had mentioned that we’d be pretty happy if we could get something like 7-8 points above chance average classification accuracy across subjects.  This is much higher than the average classification accuracy ($ mean AUC = 0.52 $) we were getting for our “best 8” untransformed, logistic regression average AUC using all times and frequencies (recall that those results were not using frequency bands like we are now, but instead look at the power spectrum at individual frequencies).  Obviously, we can’t directly compare the individual time and frequency band results to using all time and frequency features, but it’s the closest benchmark we have.  Those old results can be found <a href="http://ElPiloto.github.io/blog/2014/07/27/sleep-eeg-post-boosting-results/"> here </a> under the section “To-Do Item #2”.</p>

<p>These results are encouraging for two reasons.  First, the best time and frequency combination falls within a plausible time range.  We could talk to James to see if he has any a priori evidence to support getting results in the BETA frequency range, but at least the time isn’t too early.  Second, the AUC is pretty good on the individual subject level as we see below: most subjects are either at or above chance.</p>

<p><a href='/images/research/sleep_eeg_hilbert/best_time_freq_untransformed_sleep_lambda1.jpg' target='_blank'><img src="/images/research/sleep_eeg_hilbert/best_time_freq_untransformed_sleep_lambda1.jpg" width="700" height="350"></a></p>

<p><strong>Figure 6:</strong> Above we show the AUC for each subjects generated by performing logistic regression on the sleep data at the best time and frequency band combination with regularization parameter $ \lambda = 1 $.</p>

<p><a href='/images/research/sleep_eeg_hilbert/best_time_freq_untransformed_sleep_lambda50.jpg' target='_blank'><img src="/images/research/sleep_eeg_hilbert/best_time_freq_untransformed_sleep_lambda50.jpg" width="700" height="350"></a></p>

<p><strong>Figure 7:</strong> Same as Figure 6, except this time we set the regularization parameter $ \lambda = 50 $.</p>

<p><strong>Thoughts:</strong> Okay, so we have <strong>a</strong> time and frequency combination that gives us good classification accuracy, but this could just arise from multiple comparisons.  Sure, we can take comfort that the classification accuracy seems to peak at 175ms and degrades smoothly as we move away, but it’s also the case that the EEG power spectrum is pretty similar at those times.  <strong>SO</strong>, what would it take for me to believe these results?  Running classification on <strong>ALL</strong> of the <em>untransformed</em> sleep data features with heavy regularization and yielding good classification accuracy with weights that consistently preferred that time and frequency combination.  This is next on my to-do list, it shouldn’t take too long to get up and running.  I’d also like to add a reminder to myself that it may be worth subsampling the time dimension.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Probabilistic Logic Learning - Luc De Raedt and Kristian Kersting]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/08/05/probabilistic-logic-learning-luc-de-raedt-and-kristian-kersting/"/>
    <updated>2014-08-05T12:51:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/08/05/probabilistic-logic-learning-luc-de-raedt-and-kristian-kersting</id>
    <content type="html"><![CDATA[<h4 id="what-does-probabilistic-logic-learning-mean">What does probabilistic logic learning mean?</h4>
<p><strong>probabilistic</strong> - probabilistic representations and reasoning mechanisms <br />
<strong>logic</strong> - first order logical and relational representations (compared to propositional logic affords reasoning about objects)</p>

<h3 id="logic-glossary">Logic Glossary</h3>
<p>first-order logic $\leftrightarrow$ relational representation <br />
allows for:<br />
<strong>extensional</strong>: <code>ram(r1,c1)</code> – </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sleep EEG: Varying regularization and simulated results]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/08/01/sleep-eeg-varying-regularization-and-simulated-results/"/>
    <updated>2014-08-01T10:27:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/08/01/sleep-eeg-varying-regularization-and-simulated-results</id>
    <content type="html"><![CDATA[<h3 id="logistic-regression-untransformed-sleep-data-varying-regularization-term">Logistic Regression Untransformed Sleep Data: Varying regularization term</h3>
<p>The motivation for this line of inquiry is contained in <a href="/blog/2014/07/27/sleep-eeg-post-boosting-results/">this post</a> under the discussion section for figure 4.</p>

<p><a href='/images/research/untransformed_log_reg_lambda250and750.jpg' target='_blank'><img src="/images/research/untransformed_log_reg_lambda250and750.jpg" width="700" height="350"></a></p>

<p><strong>Figure 1:</strong> This shows the sleep classification accuracy for logistic regression using untransformed sleep data with <code>statmap_anova</code> feature selection (stat_thresh = 0.1).</p>

<p><strong>Thoughts</strong> Well this is interesting.  I had previously been using a regularization term of 1 for all the logistic regression analyses and to see this level of classification accuracy using a regularization penalty two orders of magnitude higher than previously suggests that I didn’t have much of a grasp on the role of the regularization term in this analysis.  The $\lambda = 750$ case is encouraging because it’s up there in terms of the highest average classification accuracy we’ve seen AND it includes that largest regularization term we’ve used thus far.  It’s worth investigating how far we can push regularization before it collapses, thus I’ve launched an additional analysis trying results with regularization = 1250 and 1750.  Will update this post when those results are in.  ALSO, this begs the question: should we re-run our sleep transformed analyses using stronger regularization for the wake classes?  <strong>YES</strong></p>

<p><a href='/images/research/untransformed_log_reg_lambda1250and1750.jpg' target='_blank'><img src="/images/research/untransformed_log_reg_lambda1250and1750.jpg" width="700" height="350"></a></p>

<p><strong>Figure 2:</strong> This shows the sleep classification accuracy for logistic regression using untransformed sleep data with <code>statmap_anova</code> feature selection (stat_thresh = 0.1).</p>

<p><strong>Thoughts:</strong> This still doesn’t make it seem like we’ve hit the upper bound on the regularization penalty. I’m not sure what to make of the fact that 750 = good regularzation, 1750 = good regularization, but 1250 gives pretty crappy results.  I guess I don’t have any strong theoretical justification to think classification accuracy would vary smoothly as we modify the regularization parameter.  I’m now launching sleep untransformed classification on <em>all</em> the subjects with a high regularization term.</p>

<p><a href='/images/research/untransformed_log_reg_lambda12000_ALLSUBJS.jpg' target='_blank'><img src="/images/research/untransformed_log_reg_lambda12000_ALLSUBJS.jpg" width="700" height="350"></a></p>

<p><strong>Figure 3:</strong> This shows the sleep classification accuracy for logistic regression using untransformed sleep data with <code>statmap_anova</code> feature selection (stat_thresh = 0.1).</p>

<p><strong>Thoughts:</strong> This is clearly too high for most subjects. Although <strong>some</strong> of the subjects that have been doing well in our “best 8” analysis get pretty good classification with $\lambda = 2000$, which is unsurprising given their results for $\lambda = 1750$, some other subjects (e.g. subject 7) that did well are now getting below-chance accuracy.  The flop of some of the good “best 8” subjects from above to below chance accuracy makes a good case for reducing the regularization penalty.  Thus, I’m gunna try running all subjects with a smaller value for $\lambda$ because the infrastructure is in place to do that.</p>

<h3 id="simulated-results">Simulated Results</h3>

<p><del><strong>STILL CODING</strong></del> <strong>PUT ON HOLD, GOING TO TRY HILBERT TRANSFORMED DATA ANALYSIS FIRST</strong></p>

<!--Ken is most interested in the hilbert-transformed data in the hopes that the Hilbert stuff will clean up (induce consistency across subjects) for wake.  Hopefully see good classification across subjects theta, 200-ish, also which electrodes are informative.-->
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sleep EEG: Group Meeting]]></title>
    <link href="http://ElPiloto.github.io/blog/2014/07/28/sleep-eeg-group-meeting/"/>
    <updated>2014-07-28T17:10:00-04:00</updated>
    <id>http://ElPiloto.github.io/blog/2014/07/28/sleep-eeg-group-meeting</id>
    <content type="html"><![CDATA[<h3 id="ken-succinctly-described-two-levels-of-complexity-in-our-sleep-analysis">Ken succinctly described two levels of complexity in our sleep analysis:</h3>
<ol>
  <li>How do we transform the sleep?  Recall this can be face or scene transformed, we can use correlation or the dot product, we can use data from different frequencies and different time bins in the wake data, etc.<br />
    <ul>
      <li>Perhaps we don’t need to sleep transform?</li>
      <li>Perhaps we need to exclude electrodes explicitly? We thought the McDuff importance maps method implemented this, but correlation doesn’t care about the magnitude so we need to re-evaluate this (either use dot product OR filter out electrodes by some other measure)  <strong>(TODO ITEM: dot product)</strong></li>
    </ul>
  </li>
  <li>When does reinstatement happen?  How should we score reinstatement?  If we do classification, do we just look at one time bin for the sleep?  Do we sum up classification across all time bins, etc.<br />
    <ul>
      <li>Maybe we want to use a simpler method than classification a la Staresina paper: sum correlation between template and sleep pattern and threshold to indicate replay event.   </li>
      <li>We could and should look at trial-by-trial plots of correlation across time for both the incorrect and correct pattern - eyeball the crap out of this.  <strong>(TODO ITEM)</strong></li>
    </ul>
  </li>
  <li>James also mentioned trial-by-trial variability: if cue during down phase, won’t expect reactivation in next 500 ms when all neurons are turned off.</li>
</ol>

<h3 id="behavioral-results-look-great">Behavioral Results Look great</h3>
<ol>
  <li>Spindles too rare to use to limit the sleep data   </li>
</ol>

<h3 id="additional-thoughts">Additional thoughts:</h3>
<ol>
  <li>We should leave open the option to look at ERPs for classification, although Ehren’s thoughts were that ERP winds up showing in theta band of power spectrum, plus see things in power spectrum that you don’t see in the ERPs.</li>
  <li>We can theoretically get more classification juice if we exclude forgotten items from the sleep analysis.  </li>
  <li>Waiting on James to get power spectrum for bands using Hilbert transform  </li>
  <li>We have the data to look at wake classification during wake reactivation i.e. can we classify when they’re learning the associated locations?   </li>
</ol>

<h3 id="todo-items">TODO ITEMS:</h3>
<p><strong>dot product:</strong><br />
<del>currently running sleep log reg mcduff using both faces and scenes, results will be in <code>sleep_xform_mcduff_scene_face_8subjs_dotprod.mat</code></del>  Results in post: sleep-eeg-boosting-results
<del>currently running boosting gentle log reg using both faces and scenes, results will be in <code>boosting_mcduff_best8_gentle_scene_face_dotprod.mat</code></del>Results in post: sleep-eeg-boosting-results, <strong>EXCEPT</strong> for some reason</p>

]]></content>
  </entry>
  
</feed>
