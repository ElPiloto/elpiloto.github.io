
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Sleep EEG 9 Subjects - Something Witty</title>
  <meta name="author" content="Luis R. Piloto">

  
  <meta name="description" content="EEG, hide, noarchive, sleep Sleep EEG 9 Subjects All the interpretations Hi Ken, Here’s the scoop. We can definitely classify wake data (see Figure &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://ElPiloto.github.io/blog/2014/06/23/sleep-eeg-9-subjects">
  <link href="/favicon.ico" rel="icon">
  <link href="/stylesheets/styles.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Something Witty" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <script src="/javascripts/jquery.sidr.min.js"></script>
  <script src="/javascripts/ah-blue.js"></script>
  <!-- MathJax -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
  </script>

  <script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-49251088-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head> 

<body   >
  <div class="aux-container">
    <a id="nav-toggle" href="#sidr"></a>
    <a id="search-toggle"></a>
	<h1 style="margin-left: 30px">the blog of luis piloto</h1>
</div>

<header class="header-container clearfix" id="the_header_container">
        <a href="/" align="left"><img src="/images/brain.svg" onerror="this.onerror=null; this.src='brain.png'"></a>
</header>


  <div class="main-container add-top-margin" id="the_main_container">
    <div class="main wrapper clearfix">
    	
    	<aside>
			
			  	<div class="search-container">
					<form action="http://google.com/search" method="get">
						<fieldset role="search">
							<input type="hidden" name="q" value="site:elpiloto.github.io" />
							<input class="search-field" type="text" name="q" results="0" placeholder=""/>
							<input class="submit" type="submit" value=""/>
						</fieldset>
					</form>
				</div>
			
		  <div id="main-nav">
    <nav>
        <ul>
        	<li>
        		
					<h3>Recent Posts</h3>
<ul>
	
	
    <li>
    	<a href="/blog/2014/07/01/sleep-eeg-transform-avg-pattern/">Sleep Transform Average Pattern</a>
    </li>
	
    
	
    <li>
    	<a href="/blog/2014/07/01/sleep-eeg-mcduff-transform/">Sleep Transform McDUFF</a>
    </li>
	
    
	
	
    
	
	
    
	
	
    
</ul>

				
        	</li>
        </ul>
		<ul>
			<li>
				<section>
	<h1>Other Links</h1>
	<ul>
		<li><a href="/about"> about luis piloto</a></li>
		<li><a href="/see"> look </a></li>
		<li><a href="https://github.com/Elpiloto"</a>github</li>
		<li><a href="http://compmem.princeton.edu">compmem lab</a></li>
		<li><a href="http://princeton.edu/~piet">apiet</a></li>
		<li><a href="http://bensondaled.github.io/homepage/">ben deverett</a></li>
	</ul>
</section>

			</li>
		</ul>
    </nav>
</div>

		</aside>
		
      <div>
<article>
	<header>
  <div class="article-tags">
      

<span class="categories">
  
    <a class='category' href='/blog/categories/eeg/'>EEG</a>, <a class='category' href='/blog/categories/hide/'>hide</a>, <a class='category' href='/blog/categories/noarchive/'>noarchive</a>, <a class='category' href='/blog/categories/sleep/'>sleep</a>
  
</span>


  </div>
  
    <h1>
      Sleep EEG 9 Subjects
    </h1>
  
</header>
<section>
  <h2 id="all-the-interpretations">All the interpretations</h2>

<p>Hi Ken,  </p>

<p>Here’s the scoop.  We can definitely classify wake data (see Figure 1a below) The best time bin for the wake data isn’t consistent across all subjects, but it does seem to peak at 230ms, which is consistent with Ehren’s results ( compare figure 1b to figure 4: http://compmem.princeton.edu/publications/NewmanNorman10.pdf)  Our classification results aren’t as good as Ehren’s, he had a peak AUC of 0.7, but I’m not too worried about it - what do you think?  There might be some utility to looking at classification for slightly later timebins (although Ehren’s results do peak at 200ms so we might already be looking at the best time bin)   </p>

<p><strong>So can we classify sleep?</strong> 	</p>

<p>We tried three different sleep classification methods:<br />
1. Feature selection on all the frequencies within a particular time bin of sleep data.
2. Transform the sleep data using the average pattern of activity across all electrodes at a particular time-bin and frequency of the wake data.
3. Transform the sleep data using the importance map generated by the wake classification instead of the average pattern of activity - this should weight the different electrodes according to how informative they are for wake classification.  </p>

<p>For method 1, we’re not getting any consistently classifiable timebins across subjects (figure 3a and 3b) which would have been the nicest result.</p>

<p>The good news is that methods 2 and 3 show comparable classification AUC to method 1 and sometimes do even better.  Moreover, there isn’t a link between good classification for a time bin using method 1 compared to method 2 or 3 (e.g. method 1 classification for subject 2 doesn’t do so hot for timebins 152-230, but if you look at <a href="/images/research/sleep_eeg_9_subjects_06_23_2014/sleep_xform_avg_pattern/sleep_transform_cv_auc_scene_subj2.png"> this plot</a> for method 2 classification for subject 2 - it’s pretty clear that that is a helpful time bin ).  These two observations give me confidence that the two sleep transform methods are genuinely helpful preprocessing steps.</p>

<p>Moreover, I’ve been pretty excited about these sleep transform methods because they frequently, though not always, produce strong bands of good classification for particular timebins.  Note that these timebins vary across subjects, which I’ve included below.</p>

<table>
<tr>
<td>Subj 1</td>
<td>254-336,835-886;</td>
</tr>
</table>
<p>336-454,886-964;
231-281;
859-991;
230-254;
176-308;
281-359;
886-991,303-464,336-464;</p>

<p>So a logical next question is to determine which method of the two sleep transform methods are better.  Unfortunately, I don’t get the impression that one method is better than the other.  Sometimes a subject will look okay (not particularly salient bands of good classification) for one method, but</p>

<h3 id="wake-classification-results">Wake Classification Results</h3>
<p>These are important because it’s likely we’ll want to exclude subjects with poor wake cross-validation AUC from subsequent analyses.</p>

<p><img src="/images/research/sleep_eeg_9_subjects_06_23_2014/wake_AUC_most_subjects.png" width="700" height="350" /></p>

<p><strong>Figure 1a:</strong> This shows the AUC for leave-one-out cross-validation on wake EEG data training on all the z-scored frequencies corresponding to a particular time bin as indicated on the y-axis.  The AUC was calculating by training a classifier that distinguishes between all classes, but only testing on patterns that corresponded to either a celebrity or a landmark.  The AUC was calculated by feeding in the difference between the output for the celebrity one-vs-all classifier and the landmark one-vs-all classifier for each cross-validation fold and the plotted values show the mean AUC across all cross-validation folds.  We had previously looked at the cross-validation accuracy for the first two subjects across a wider range of times, but narrowed it down to these four windows.</p>

<p><code>plot_loopify_time_sweep_results_AUC.m </code>  <br />
<code>classify_piloy_log_reg_time_sweep_driver.m </code>      </p>

<p><img src="/images/research/sleep_eeg_9_subjects_06_23_2014/wake_auc_avgd.png" width="700" height="350" /></p>

<p><strong>Figure 1b:</strong> Average AUC per time bin</p>

<h3 id="sleep-cross-validation-classification-all-frequencies-per-time-bin">Sleep Cross-Validation Classification: All Frequencies Per Time Bin</h3>
<p><strong>NOTE:</strong> These results were supposed to be for performing feature selection, but I accidentally set the feature selection statistical threshold to 1, which is the same as not using feature selection.  <del>Re-running these results with feature selection.</del>  The results actually containing feature selection are just below.</p>

<p><img src="/images/research/sleep_eeg_9_subjects_06_23_2014/all_9subjects_sleep_CV_AUC_feature_select.png" width="700" height="350" />
<strong>Figure 2a)</strong> We plot the AUC for classification of celebrity vs. landmarks during sleep across all our subjects (y-axis).  This was calculated by performing cross-validation (somewhere between 15-fold and 40-fold depending on the number of sleep patterns available) using all frequencies z-scored across electrodes for a particular timebin (x-axis). <br />
<img src="/images/research/sleep_eeg_9_subjects_06_23_2014/all_9subjects_sleep_CV_AUC_feature_select_PVAL.png" width="700" height="350" />
<strong>Figure 2b)</strong> We plot the p-values for combinations of subjects and time bins with sleep cross-validation AUC values that are calculated via a shuffled permutation test whereby the labels of the classes are shuffled, we train a classifier with the shuffled patterns, and look at the cross-validation AUC for this shuffled dataset. Areas in red have p-values &gt; 0.05.
<img src="/images/research/sleep_eeg_9_subjects_06_23_2014/all_9subjects_sleep_CV_acc_feature_select.png" width="700" height="350" />
<strong>Figure 2c)</strong> Instead of calculating the AUC, we plot the classification accuracy - this should be pretty similar to Figure 2b.
<img src="/images/research/sleep_eeg_9_subjects_06_23_2014/all_9subjects_sleep_CV_acc_feature_select_PVAL.png" width="700" height="350" />
<strong>Figure 2d)</strong> Here we plot the p-values for the classification accuracies.</p>

<h3 id="sleep-cross-validation-classification-feature-selection-all-frequencies-per-time-bin">Sleep Cross-Validation Classification Feature Selection: All Frequencies Per Time Bin</h3>

<p><img src="/images/research/sleep_eeg_9_subjects_06_23_2014/9_subjects_CV_ACTUAL_AUC_feature_select.png" width="700" height="350" />
<strong>Figure 3a)</strong> We plot the AUC for classification of celebrity vs. landmarks during sleep across all our subjects (y-axis).  This was calculated by performing cross-validation (somewhere between 15-fold and 40-fold depending on the number of sleep patterns available) using all frequencies z-scored across electrodes for a particular timebin (x-axis). <br />
<img src="/images/research/sleep_eeg_9_subjects_06_23_2014/9_subjects_CV_ACTUAL_AUC_feature_select_PVAL.png" width="700" height="350" />
<strong>Figure 3b)</strong> We plot the p-values for combinations of subjects and time bins with sleep cross-validation AUC values that are calculated via a shuffled permutation test whereby the labels of the classes are shuffled, we train a classifier with the shuffled patterns, and look at the cross-validation AUC for this shuffled dataset. Areas in red have p-values &gt; 0.05.
<img src="/images/research/sleep_eeg_9_subjects_06_23_2014/9_subjects_CV_ACTUAL_acc_feature_select.png" width="700" height="350" />
<strong>Figure 3c)</strong> Instead of calculating the AUC, we plot the classification accuracy - this should be pretty similar to Figure 2b.
<img src="/images/research/sleep_eeg_9_subjects_06_23_2014/9_subjects_CV_ACTUAL_acc_feature_select_PVAL.png" width="700" height="350" />
<strong>Figure 3d)</strong> Here we plot the p-values for the classification accuracies.</p>

<h3 id="sleep-cross-validation-transform-sleep-pattern-by-average-wake-pattern">Sleep Cross-Validation: Transform Sleep Pattern By Average Wake Pattern</h3>
<p><a href="/blog/2014/07/01/sleep-eeg-transform-avg-pattern/"> dump of plots </a>   </p>

<p>We have 4 x 3 plots per subject (4 plots (AUC, accuracy, and p-val map for both of those) for each result, 3 different results: one for transforming the sleep data with the average face pattern, one for transforming with the average scene pattern, and one for transforming with the difference between the average face and average scene)</p>

<h3 id="sleep-cross-validation-transform-sleep-pattern-by-mcduff-importance-map">Sleep Cross-Validation: Transform Sleep Pattern By McDuff Importance Map</h3>
<p><a href="/blog/2014/07/01/sleep-eeg-mcduff-transform/"> dump of plots </a>   </p>

<p>We have 4 x 3 plots per subject (4 plots (AUC, accuracy, and p-val map for both of those) for each result, 3 different results: one for transforming the sleep data with the face mcduff importance map, one for transforming with the scene mcduff importance map, and one for transforming with the difference between the face and scene importance maps)</p>

</section>
<footer>
  <div class="article-date">
      








  


<time datetime="2014-06-23T12:14:00-04:00" pubdate data-updated="true">Jun 23<span>rd</span>, 2014</time>
  </div>
</footer>

	
</article>
</div>

    </div>
  </div>
  <footer class="main-footer">
	<section class="interior-footer">
		<span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
	</section>
</footer>


  








  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>




</body>
</html>
